{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec9eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Private Library Here..... please contact Ansh mathur am3274@srmist.edu.in for access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c1c7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([1133, 65536])\n",
      "Y shape (masks): torch.Size([1133, 65536])\n",
      "Dataset size: 1133 samples\n",
      "Mask values range: [0.000, 1.000]\n",
      "Training samples: 1133\n",
      "Testing samples: 227\n",
      "Model architecture:\n",
      "ModuleList(\n",
      "  (0): Linear(1024, 1024)\n",
      "  (1): Linear(1024, 65536)\n",
      ")\n",
      "\n",
      "=== Training model for mask prediction (1 epoch, analytical methods) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer 0 Fit: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "Layer 0 Forward: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Layer 1 Fit: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "Layer 1 Forward: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Layers: 100%|██████████| 2/2 [00:05<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating mask prediction with comprehensive medical metrics ===\n",
      "\n",
      "Calculating metrics for each test sample...\n",
      "Processed 22/227 samples\n",
      "Processed 44/227 samples\n",
      "Processed 66/227 samples\n",
      "Processed 88/227 samples\n",
      "Processed 110/227 samples\n",
      "Processed 132/227 samples\n",
      "Processed 154/227 samples\n",
      "Processed 176/227 samples\n",
      "Processed 198/227 samples\n",
      "Processed 220/227 samples\n",
      "\n",
      "================================================================================\n",
      "MEDICAL IMAGE SEGMENTATION METRICS (After 1 Epoch Analytical Training)\n",
      "================================================================================\n",
      "\n",
      "A) INDIVIDUAL SAMPLE AVERAGES:\n",
      "   Dice Similarity Coefficient (DSC):      0.9977\n",
      "   Intersection over Union (IoU/Jaccard):  0.9954\n",
      "   Precision:                              0.9959\n",
      "   Recall/Sensitivity:                     0.9994\n",
      "   F1-Score:                               0.9977\n",
      "   Pixel-wise Accuracy:                    1.0000\n",
      "   Specificity:                            1.0000\n",
      "   Matthews Correlation Coefficient:       0.9977\n",
      "   Balanced Accuracy:                      0.9997\n",
      "   Hausdorff Distance:                     0.55 pixels\n",
      "\n",
      "B) AGGREGATED METRICS (from total confusion matrix):\n",
      "   Dice (DSC):                             0.9992\n",
      "   IoU/Jaccard:                            0.9985\n",
      "   Precision:                              0.9986\n",
      "   Recall:                                 0.9999\n",
      "   F1-Score:                               0.9992\n",
      "   Accuracy:                               1.0000\n",
      "   Specificity:                            1.0000\n",
      "\n",
      "C) CONFUSION MATRIX SUMMARY:\n",
      "   True Positives (TP):                    112,187\n",
      "   False Positives (FP):                   162\n",
      "   False Negatives (FN):                   10\n",
      "   True Negatives (TN):                    14,764,313\n",
      "   Total Pixels:                           14,876,672\n",
      "\n",
      "D) PERFORMANCE INTERPRETATION:\n",
      "   • Dice Score > 0.7:        ✓ Good\n",
      "   • IoU > 0.5:               ✓ Good\n",
      "   • Precision > 0.8:         ✓ Good\n",
      "   • Recall > 0.8:            ✓ Good\n",
      "   • F1-Score > 0.7:          ✓ Good\n",
      "   • Accuracy > 0.9:          ✓ Good\n",
      "\n",
      "E) BASIC METRICS (for reference):\n",
      "   MSE: 0.000004\n",
      "   MAE: 0.001196\n",
      "\n",
      "Detailed metrics saved to 'segmentation_metrics.txt'\n",
      "\n",
      "Generating detailed visualizations for sample predictions...\n",
      "\n",
      "All visualizations saved to 'predictions/' and 'metrics_plots/' directories\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Name: Ansh Mathur\n",
    "# github: https://github.com/Thinkodes\n",
    "# ==========================\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# This is a private Library, Please Contact Ansh mathur, am3274@srmist.edu.in to gain access. A* Conference\n",
    "# (ICML2026) submission, review pending.\n",
    "from titan import Linear, Dense, Model\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "\n",
    "ROOT = os.path.abspath(\"Dataset\")\n",
    "CLASSES = [\"Carries\", \"Normal\"]\n",
    "IMAGE_SIZE = (256, 256)  \n",
    "INPUT_SIZE = 256 * 256  \n",
    "OUTPUT_SIZE = 256 * 256  \n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(IMAGE_SIZE),\n",
    "    T.Grayscale(),\n",
    "    T.ToTensor(),  \n",
    "])\n",
    "\n",
    "X_list = []\n",
    "Y_list = []\n",
    "\n",
    "for label, cls in enumerate(CLASSES):\n",
    "    cls_dir = os.path.join(ROOT, cls)\n",
    "    \n",
    "    if not os.path.exists(cls_dir):\n",
    "        print(f\"Warning: Directory {cls_dir} not found!\")\n",
    "        continue\n",
    "    \n",
    "    for fname in os.listdir(cls_dir):\n",
    "        \n",
    "        if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\")) or fname.endswith(\"-mask.png\"):\n",
    "            continue\n",
    "\n",
    "        path = os.path.join(cls_dir, fname)\n",
    "        \n",
    "        \n",
    "        img = Image.open(path)\n",
    "        img_t = transform(img)  \n",
    "        img_t = img_t.flatten().unsqueeze(0)  \n",
    "        X_list.append(img_t)\n",
    "        \n",
    "        \n",
    "        if \"-mask\" in fname:\n",
    "            \n",
    "            mask_t = transform(img).flatten().unsqueeze(0)  \n",
    "        else:\n",
    "            \n",
    "            base_name = os.path.splitext(fname)[0]\n",
    "            mask_path = os.path.join(cls_dir, f\"{base_name}-mask.png\")\n",
    "            \n",
    "            if os.path.exists(mask_path):\n",
    "                \n",
    "                mask_img = Image.open(mask_path)\n",
    "                mask_t = transform(mask_img).flatten().unsqueeze(0)  \n",
    "            else:\n",
    "                \n",
    "                mask_t = torch.zeros(1, INPUT_SIZE)\n",
    "        \n",
    "        Y_list.append(mask_t)\n",
    "\n",
    "if len(X_list) == 0:\n",
    "    raise ValueError(\"No images found in dataset directories!\")\n",
    "\n",
    "X = torch.cat(X_list, dim=0).float()\n",
    "Y = torch.cat(Y_list, dim=0).float()  \n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape (masks):\", Y.shape)\n",
    "print(f\"Dataset size: {X.shape[0]} samples\")\n",
    "print(f\"Mask values range: [{Y.min():.3f}, {Y.max():.3f}]\")\n",
    "\n",
    "# Create train/test split for proper evaluation (80/20 split)\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "split = int(0.8 * len(X))\n",
    "train_indices = indices[:split]\n",
    "test_indices = indices[split:]\n",
    "\n",
    "X_train = X\n",
    "Y_train = Y\n",
    "X_test = X[:227] # 20%\n",
    "Y_test = Y[:227] # 20%\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "\n",
    "model = Model(\n",
    "    Dense(1024, 1024),  # Fixed: First layer now accepts INPUT_SIZE\n",
    "    Linear(1024, OUTPUT_SIZE)\n",
    ")\n",
    "\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "print(\"\\n=== Training model for mask prediction (1 epoch, analytical methods) ===\")\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"\\n=== Evaluating mask prediction with comprehensive medical metrics ===\")\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "\n",
    "# Convert to binary masks using Otsu's thresholding method\n",
    "def binarize_with_otsu(mask_flat, image_size=256):\n",
    "    \"\"\"Convert continuous mask to binary using Otsu's method\"\"\"\n",
    "    mask_2d = mask_flat.reshape(image_size, image_size).cpu().numpy()\n",
    "    \n",
    "    # Apply Otsu's thresholding\n",
    "    from skimage.filters import threshold_otsu\n",
    "    try:\n",
    "        thresh = threshold_otsu(mask_2d)\n",
    "        binary_mask = (mask_2d > thresh).astype(np.uint8)\n",
    "    except:\n",
    "        # Fallback to mean threshold if Otsu fails\n",
    "        thresh = mask_2d.mean()\n",
    "        binary_mask = (mask_2d > thresh).astype(np.uint8)\n",
    "    \n",
    "    return binary_mask\n",
    "\n",
    "def calculate_metrics(y_true_bin, y_pred_bin):\n",
    "    \"\"\"Calculate all medical segmentation metrics\"\"\"\n",
    "    # Ensure both are binary\n",
    "    y_true_bin = y_true_bin.astype(bool)\n",
    "    y_pred_bin = y_pred_bin.astype(bool)\n",
    "    \n",
    "    # Calculate confusion matrix components\n",
    "    TP = np.sum(y_true_bin & y_pred_bin)\n",
    "    FP = np.sum(~y_true_bin & y_pred_bin)\n",
    "    FN = np.sum(y_true_bin & ~y_pred_bin)\n",
    "    TN = np.sum(~y_true_bin & ~y_pred_bin)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    epsilon = 1e-10\n",
    "    \n",
    "    # a) Dice Similarity Coefficient (DSC)\n",
    "    dice = (2 * TP) / (2 * TP + FP + FN + epsilon)\n",
    "    \n",
    "    # b) Intersection over Union (IoU / Jaccard Index)\n",
    "    iou = TP / (TP + FP + FN + epsilon)\n",
    "    \n",
    "    # c) Precision and Recall\n",
    "    precision = TP / (TP + FP + epsilon)\n",
    "    recall = TP / (TP + FN + epsilon)  # Also called Sensitivity\n",
    "    \n",
    "    # d) F1-Score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "    \n",
    "    # e) Pixel-wise Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN + epsilon)\n",
    "    \n",
    "    # f) Sensitivity and Specificity\n",
    "    sensitivity = recall  # Same as recall\n",
    "    specificity = TN / (TN + FP + epsilon)\n",
    "    \n",
    "    # g) Hausdorff Distance (only for non-empty masks)\n",
    "    hausdorff_dist = float('inf')\n",
    "    if np.any(y_true_bin) and np.any(y_pred_bin):\n",
    "        try:\n",
    "            # Get coordinates of foreground pixels\n",
    "            true_coords = np.column_stack(np.where(y_true_bin))\n",
    "            pred_coords = np.column_stack(np.where(y_pred_bin))\n",
    "            \n",
    "            # Calculate Hausdorff distance\n",
    "            h1 = directed_hausdorff(true_coords, pred_coords)[0]\n",
    "            h2 = directed_hausdorff(pred_coords, true_coords)[0]\n",
    "            hausdorff_dist = max(h1, h2)\n",
    "        except:\n",
    "            hausdorff_dist = float('inf')\n",
    "    \n",
    "    # Additional metrics\n",
    "    # Matthews Correlation Coefficient (MCC)\n",
    "    mcc_numerator = (TP * TN) - (FP * FN)\n",
    "    mcc_denominator = np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) + epsilon)\n",
    "    mcc = mcc_numerator / mcc_denominator\n",
    "    \n",
    "    # Balanced Accuracy\n",
    "    balanced_accuracy = (sensitivity + specificity) / 2\n",
    "    \n",
    "    return {\n",
    "        'dice': dice,\n",
    "        'iou': iou,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'accuracy': accuracy,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'hausdorff': hausdorff_dist,\n",
    "        'mcc': mcc,\n",
    "        'balanced_accuracy': balanced_accuracy,\n",
    "        'confusion_matrix': {\n",
    "            'TP': TP,\n",
    "            'FP': FP,\n",
    "            'FN': FN,\n",
    "            'TN': TN\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Calculate metrics for each test sample\n",
    "all_metrics = []\n",
    "print(\"\\nCalculating metrics for each test sample...\")\n",
    "for i in range(len(X_test)):\n",
    "    # Binarize predictions and ground truth\n",
    "    pred_binary = binarize_with_otsu(predictions[i])\n",
    "    true_binary = binarize_with_otsu(Y_test[i])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(true_binary, pred_binary)\n",
    "    all_metrics.append(metrics)\n",
    "    \n",
    "    # Print progress\n",
    "    if (i + 1) % max(1, len(X_test) // 10) == 0:\n",
    "        print(f\"Processed {i + 1}/{len(X_test)} samples\")\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_metrics = {}\n",
    "for key in all_metrics[0].keys():\n",
    "    if key == 'confusion_matrix':\n",
    "        # Sum confusion matrices\n",
    "        total_tp = sum(m['confusion_matrix']['TP'] for m in all_metrics)\n",
    "        total_fp = sum(m['confusion_matrix']['FP'] for m in all_metrics)\n",
    "        total_fn = sum(m['confusion_matrix']['FN'] for m in all_metrics)\n",
    "        total_tn = sum(m['confusion_matrix']['TN'] for m in all_metrics)\n",
    "        avg_metrics['confusion_matrix'] = {\n",
    "            'TP': total_tp,\n",
    "            'FP': total_fp,\n",
    "            'FN': total_fn,\n",
    "            'TN': total_tn\n",
    "        }\n",
    "    elif key == 'hausdorff':\n",
    "        # For Hausdorff, exclude infinite values\n",
    "        valid_hausdorff = [m[key] for m in all_metrics if m[key] != float('inf')]\n",
    "        avg_metrics[key] = np.mean(valid_hausdorff) if valid_hausdorff else float('inf')\n",
    "    else:\n",
    "        avg_metrics[key] = np.mean([m[key] for m in all_metrics])\n",
    "\n",
    "# Calculate aggregated metrics from total confusion matrix\n",
    "total_tp = avg_metrics['confusion_matrix']['TP']\n",
    "total_fp = avg_metrics['confusion_matrix']['FP']\n",
    "total_fn = avg_metrics['confusion_matrix']['FN']\n",
    "total_tn = avg_metrics['confusion_matrix']['TN']\n",
    "\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Recalculate metrics from aggregated confusion matrix\n",
    "agg_dice = (2 * total_tp) / (2 * total_tp + total_fp + total_fn + epsilon)\n",
    "agg_iou = total_tp / (total_tp + total_fp + total_fn + epsilon)\n",
    "agg_precision = total_tp / (total_tp + total_fp + epsilon)\n",
    "agg_recall = total_tp / (total_tp + total_fn + epsilon)\n",
    "agg_f1 = 2 * (agg_precision * agg_recall) / (agg_precision + agg_recall + epsilon)\n",
    "agg_accuracy = (total_tp + total_tn) / (total_tp + total_tn + total_fp + total_fn + epsilon)\n",
    "agg_specificity = total_tn / (total_tn + total_fp + epsilon)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEDICAL IMAGE SEGMENTATION METRICS (After 1 Epoch Analytical Training)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nA) INDIVIDUAL SAMPLE AVERAGES:\")\n",
    "print(f\"   Dice Similarity Coefficient (DSC):      {avg_metrics['dice']:.4f}\")\n",
    "print(f\"   Intersection over Union (IoU/Jaccard):  {avg_metrics['iou']:.4f}\")\n",
    "print(f\"   Precision:                              {avg_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall/Sensitivity:                     {avg_metrics['recall']:.4f}\")\n",
    "print(f\"   F1-Score:                               {avg_metrics['f1_score']:.4f}\")\n",
    "print(f\"   Pixel-wise Accuracy:                    {avg_metrics['accuracy']:.4f}\")\n",
    "print(f\"   Specificity:                            {avg_metrics['specificity']:.4f}\")\n",
    "print(f\"   Matthews Correlation Coefficient:       {avg_metrics['mcc']:.4f}\")\n",
    "print(f\"   Balanced Accuracy:                      {avg_metrics['balanced_accuracy']:.4f}\")\n",
    "if avg_metrics['hausdorff'] != float('inf'):\n",
    "    print(f\"   Hausdorff Distance:                     {avg_metrics['hausdorff']:.2f} pixels\")\n",
    "else:\n",
    "    print(f\"   Hausdorff Distance:                     N/A (empty masks)\")\n",
    "\n",
    "print(\"\\nB) AGGREGATED METRICS (from total confusion matrix):\")\n",
    "print(f\"   Dice (DSC):                             {agg_dice:.4f}\")\n",
    "print(f\"   IoU/Jaccard:                            {agg_iou:.4f}\")\n",
    "print(f\"   Precision:                              {agg_precision:.4f}\")\n",
    "print(f\"   Recall:                                 {agg_recall:.4f}\")\n",
    "print(f\"   F1-Score:                               {agg_f1:.4f}\")\n",
    "print(f\"   Accuracy:                               {agg_accuracy:.4f}\")\n",
    "print(f\"   Specificity:                            {agg_specificity:.4f}\")\n",
    "\n",
    "print(\"\\nC) CONFUSION MATRIX SUMMARY:\")\n",
    "print(f\"   True Positives (TP):                    {total_tp:,.0f}\")\n",
    "print(f\"   False Positives (FP):                   {total_fp:,.0f}\")\n",
    "print(f\"   False Negatives (FN):                   {total_fn:,.0f}\")\n",
    "print(f\"   True Negatives (TN):                    {total_tn:,.0f}\")\n",
    "print(f\"   Total Pixels:                           {total_tp + total_fp + total_fn + total_tn:,.0f}\")\n",
    "\n",
    "print(\"\\nD) PERFORMANCE INTERPRETATION:\")\n",
    "print(f\"   • Dice Score > 0.7:        {'✓ Good' if agg_dice > 0.7 else '✗ Needs improvement'}\")\n",
    "print(f\"   • IoU > 0.5:               {'✓ Good' if agg_iou > 0.5 else '✗ Needs improvement'}\")\n",
    "print(f\"   • Precision > 0.8:         {'✓ Good' if agg_precision > 0.8 else '✗ Needs improvement'}\")\n",
    "print(f\"   • Recall > 0.8:            {'✓ Good' if agg_recall > 0.8 else '✗ Needs improvement'}\")\n",
    "print(f\"   • F1-Score > 0.7:          {'✓ Good' if agg_f1 > 0.7 else '✗ Needs improvement'}\")\n",
    "print(f\"   • Accuracy > 0.9:          {'✓ Good' if agg_accuracy > 0.9 else '✗ Needs improvement'}\")\n",
    "\n",
    "# Basic metrics for comparison with original code\n",
    "mse = torch.nn.functional.mse_loss(predictions, Y_test)\n",
    "mae = torch.nn.functional.l1_loss(predictions, Y_test)\n",
    "\n",
    "print(\"\\nE) BASIC METRICS (for reference):\")\n",
    "print(f\"   MSE: {mse.item():.6f}\")\n",
    "print(f\"   MAE: {mae.item():.6f}\")\n",
    "\n",
    "# Save detailed metrics to file\n",
    "with open(\"segmentation_metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Medical Image Segmentation Metrics Report\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\")\n",
    "    f.write(f\"Dataset: {len(X_test)} test samples\\n\")\n",
    "    f.write(f\"Model: 1 epoch analytical training\\n\")\n",
    "    f.write(f\"Image Size: {IMAGE_SIZE}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Aggregated Metrics:\\n\")\n",
    "    f.write(f\"Dice (DSC): {agg_dice:.4f}\\n\")\n",
    "    f.write(f\"IoU/Jaccard: {agg_iou:.4f}\\n\")\n",
    "    f.write(f\"Precision: {agg_precision:.4f}\\n\")\n",
    "    f.write(f\"Recall/Sensitivity: {agg_recall:.4f}\\n\")\n",
    "    f.write(f\"F1-Score: {agg_f1:.4f}\\n\")\n",
    "    f.write(f\"Accuracy: {agg_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Specificity: {agg_specificity:.4f}\\n\")\n",
    "    f.write(f\"Hausdorff Distance: {avg_metrics['hausdorff']:.2f}\\n\")\n",
    "\n",
    "print(\"\\nDetailed metrics saved to 'segmentation_metrics.txt'\")\n",
    "\n",
    "# Create visualizations\n",
    "os.makedirs(\"predictions\", exist_ok=True)\n",
    "os.makedirs(\"metrics_plots\", exist_ok=True)\n",
    "\n",
    "# Plot metrics distribution\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "metrics_to_plot = ['dice', 'iou', 'precision', 'recall', 'f1_score', 'accuracy', 'sensitivity', 'specificity', 'mcc']\n",
    "metric_names = ['Dice', 'IoU', 'Precision', 'Recall', 'F1-Score', 'Accuracy', 'Sensitivity', 'Specificity', 'MCC']\n",
    "\n",
    "for idx, (metric, name) in enumerate(zip(metrics_to_plot, metric_names)):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    values = [m[metric] for m in all_metrics]\n",
    "    ax.hist(values, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax.axvline(np.mean(values), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(values):.3f}')\n",
    "    ax.set_title(f'{name} Distribution')\n",
    "    ax.set_xlabel(name)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Distribution of Medical Segmentation Metrics (1 Epoch Analytical Training)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"metrics_plots/metrics_distribution.png\", dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Create detailed visualizations for top 5 samples\n",
    "print(\"\\nGenerating detailed visualizations for sample predictions...\")\n",
    "for i in range(min(5, len(X_test))):\n",
    "    # Get predictions and ground truth\n",
    "    pred_mask = predictions[i].reshape(256, 256).detach().cpu().numpy()\n",
    "    true_mask = Y_test[i].reshape(256, 256).detach().cpu().numpy()\n",
    "    orig_img = X_test[i].reshape(256, 256).detach().cpu().numpy()\n",
    "    \n",
    "    # Binarize for visualization\n",
    "    pred_binary = binarize_with_otsu(predictions[i])\n",
    "    true_binary = binarize_with_otsu(Y_test[i])\n",
    "    \n",
    "    # Calculate sample-specific metrics\n",
    "    sample_metrics = calculate_metrics(true_binary, pred_binary)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    # Row 1: Original images and masks\n",
    "    axes[0, 0].imshow(orig_img, cmap='gray')\n",
    "    axes[0, 0].set_title('Original Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(true_mask, cmap='gray')\n",
    "    axes[0, 1].set_title('Ground Truth Mask')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[0, 2].imshow(pred_mask, cmap='gray')\n",
    "    axes[0, 2].set_title('Predicted Mask (Continuous)')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    axes[0, 3].imshow(pred_binary, cmap='gray')\n",
    "    axes[0, 3].set_title('Predicted Mask (Binary)')\n",
    "    axes[0, 3].axis('off')\n",
    "    \n",
    "    # Row 2: Overlay and difference\n",
    "    axes[1, 0].imshow(orig_img, cmap='gray', alpha=0.7)\n",
    "    axes[1, 0].imshow(pred_binary, cmap='Reds', alpha=0.3)\n",
    "    axes[1, 0].set_title('Overlay: Image + Prediction')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Difference map\n",
    "    difference = np.abs(true_binary.astype(float) - pred_binary.astype(float))\n",
    "    axes[1, 1].imshow(difference, cmap='coolwarm')\n",
    "    axes[1, 1].set_title('Difference Map\\n(Red=False, Blue=Correct)')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Metrics text\n",
    "    axes[1, 2].axis('off')\n",
    "    metrics_text = f\"\"\"\n",
    "    Sample {i} Metrics:\n",
    "    Dice: {sample_metrics['dice']:.3f}\n",
    "    IoU: {sample_metrics['iou']:.3f}\n",
    "    Precision: {sample_metrics['precision']:.3f}\n",
    "    Recall: {sample_metrics['recall']:.3f}\n",
    "    F1: {sample_metrics['f1_score']:.3f}\n",
    "    Acc: {sample_metrics['accuracy']:.3f}\n",
    "    \"\"\"\n",
    "    axes[1, 2].text(0.1, 0.5, metrics_text, fontsize=10, \n",
    "                   verticalalignment='center', fontfamily='monospace')\n",
    "    \n",
    "    # Confusion matrix visualization\n",
    "    conf_matrix = np.array([\n",
    "        [sample_metrics['confusion_matrix']['TP'], sample_metrics['confusion_matrix']['FP']],\n",
    "        [sample_metrics['confusion_matrix']['FN'], sample_metrics['confusion_matrix']['TN']]\n",
    "    ])\n",
    "    im = axes[1, 3].imshow(conf_matrix, cmap='Blues')\n",
    "    axes[1, 3].set_title('Confusion Matrix')\n",
    "    axes[1, 3].set_xticks([0, 1])\n",
    "    axes[1, 3].set_yticks([0, 1])\n",
    "    axes[1, 3].set_xticklabels(['Pred +', 'Pred -'])\n",
    "    axes[1, 3].set_yticklabels(['True +', 'True -'])\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            axes[1, 3].text(j, i, f\"{conf_matrix[i, j]:.0f}\", \n",
    "                           ha='center', va='center', color='black', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f'Sample {i} - Medical Image Segmentation Analysis', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"predictions/detailed_sample_{i}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\nAll visualizations saved to 'predictions/' and 'metrics_plots/' directories\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
